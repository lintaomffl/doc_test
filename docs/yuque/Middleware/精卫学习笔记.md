# 精卫学习笔记

参考的链接：[https://open.atatech.org/articles/147838#0](https://open.atatech.org/articles/147838#0)<br />[https://yuque.antfin-inc.com/jingwei3/user_wiki/simple_into](https://yuque.antfin-inc.com/jingwei3/user_wiki/simple_into)<br />[https://yuque.antfin-inc.com/jingwei3/user_wiki/sygwez](https://yuque.antfin-inc.com/jingwei3/user_wiki/sygwez)
<a name="sDngM"></a>
## 基本简介
精卫是一款在线数据同步工具,具有很高的实时性、低延迟以及失败重试保证数据不丢失等特点。<br />主要为了应对：

1. **迁库、拆库、扩容**： 这类需求，在集团内很常见，经常有机房迁移下线的时候，这时需要把数据从A库挪到B库。以及之前设计的是单库单表，数据量太大不能满足需求，需要进行拆库扩容。对于这类情况，就可以使用精卫全量+增量，并且利用新的分库分表规则，把老数据迁移到新库。
1. **冗余表同步**： 很多下游系统需要依赖上游系统的数据。很典型的例子，交易订单表，被很多下游系统需要，比如，航旅需要同步单独的航旅订单，彩票需要同步彩票订单。可以概括为A库里的a表同步到B库里的b表，可能需要应用过滤条件，可能需要过滤部分字段，可能需要允许字段的映射匹配。像这些常规需求，都已经内置支持。
1. **正反向关系表同步**： 使用tddl的分库分表方案以后，会经常性的遇到这样的需求：买家需要查看我买到的订单、卖家需要查看我卖出的宝贝；既需要查看关注我的人，也需要看到我关注的人。这种正反两种维度的查询需求，就可以使用精卫异步同步做到。开发者在应用里只需要操作主表，另外从表的数据异步同步获得。同步的延迟一般在几十毫秒以内，即便用户操作完立刻查看结果，也能做到基本不影响用户的体验。
1. **索引表同步**: 分库分表以后，查询需求不止正向、反向两种，而是更多的查询维度。这时可以根据需求建立索引表，就像mysql的建立索引一样。查询时，先到索引表查询出满足条件的一批主键id，然后再到主表select in回补全字段数据。这样，就算分库分表，也可以做到对分析类olap场景的支持。 操作日志表同步 这种需求相对以上几个来说小众，例如diamond的配置表（config_info），需要把用户的每次操作的变更记录同步到历史表（his_config_info）。可以利用精卫的增量同步，异步同步过去，不需要应用里编写代码。精卫同步服务内置的action转换，可以自动做到update类型的消息，转成insert到目标表执行。

![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2020/png/304852/1591325289300-a8a5d88a-49c9-4a2f-930e-145db497c681.png#align=left&display=inline&height=385&margin=%5Bobject%20Object%5D&name=image.png&originHeight=980&originWidth=1306&size=548604&status=done&style=none&width=513)
<a name="M2HrY"></a>
## 预备知识
<a name="jvldf"></a>
### 读写分离——主从复制
目的：因为数据的写所消耗时间相比读要长很多，同数据库同时操作会影响读的效率，为了保证读写效率，db层以“主写从读”的方式作均衡。<br />![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/198393/1563388690785-c5236b08-e657-4ca9-b2bb-dcc519f7dbfe.png#align=left&display=inline&height=222&margin=%5Bobject%20Object%5D&name=image.png&originHeight=251&originWidth=640&size=106051&status=done&style=none&width=565)<br />原理：主要是三个线程的协作<br />a .首先由slave启动“start slave”命令根据之前“change master”命令指定的数据创建一个IO线程与指定的master建立长连接，并告知其开始复制的binlog文件和复制起始位置，每隔既定的时间发送复制请求；<br />      b. master数据库发现有slave的io线程链接上时，会为其单独创建一个log dump线程，用于相应slave的io请求从上一次复制结束位置（没有就用io指定起始位置）开始复制当前最新数据给slave的io线程（此时上锁），io线程将接收到的数据写入salve中中继日志relay log文件中；<br />c. slave中的sql线程检测到中继日志文件发生更新后，会立即对其新增内容按照内容的binlog level进行解析，然后在数据库内执行，完成主从复制。<br /> <br />其中对于master的dump线程和slave的io线程之间的交互还包括有三种模式：<br />**异步模式（默认）：**<br />![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/198393/1563368330303-cc714203-df8e-44fa-a7e8-dddf1f188477.png#align=left&display=inline&height=194&margin=%5Bobject%20Object%5D&name=image.png&originHeight=282&originWidth=640&size=119738&status=done&style=none&width=441)<br />**同步模式：**<br />![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/198393/1563368382751-7a9c34dc-8f47-4f72-831f-a4317c3b6c50.png#align=left&display=inline&height=199&margin=%5Bobject%20Object%5D&name=image.png&originHeight=299&originWidth=640&size=161719&status=done&style=none&width=427)<br />**半同步模式：**由于全同步模式中万一slave链接断开，那么master的用户线程将被阻塞，因此衍生出此模式：master在经历一段时间（可通过修改 slave_net_timeout参数修改）还没得到ack响应将会自动进入异步模式，并且只需要所链接的slave中的任何一个返回ack即可。<br /> <br />【时延的问题】：主从复制默认异步操作，那么在用户提交修改sql到master后从slave数据库读取的内容可能是旧数据。<br />解决方法

1. 将复制操作设置为半同步方式；——写效率降低
1. 代理层记录上一个dml的ip，一段时间内来自这个ip的dql走master进行查询；——仅此ip，且写锁影响读效率，读写分离就没意义了。
1. 代理层接收dql时向数据库集群发送此table的count请求，当master的count行数与slave一致时才进入slave查询，否则进入master查询。——update语句无法识别
1. 引入缓存，数据更新后更新缓存，查询先查缓存，查不到再去数据库查。——缓存不一定可靠，宕机则无
1. 分库分表，降低负载和时延——成本大，只是降低，不能解决

【目前大部分系统为了保证系统数据的一致性，还是选择了主读主写】<br />

<a name="allHX"></a>
### 预备知识——数据恢复
由于数据库的操作都被记录在了binlog文件中，因此当数据库的数据意外丢失或被濡染可以通过解析执行既定时间段的binlog文件从而恢复出对应的数据。
<a name="uOKd9"></a>
### 预备知识——异地多活
异地多活场景下，跨数据中心之间的数据同步。这种场景的下，多个数据中心都需要写入数据，并且往对方同步。
<a name="MTIo0"></a>
### 预备知识——数据同步
对于有些业务需求需要在更新完数据库之后在其他地方需要同步更新，比如更新缓存、更新搜索引擎的索引以及发送MQ消息等等。对于常规解决方案是异步去执行这些操作，但是执行的这些操作可能会失败，但是数据库确实是操作成功的导致数据不一致的情况。对于这种情况，我们可以使用一个组件，在请求方模拟“主从同步”的salve的方式对master的binlog文件进行解析处理，失败后重试即可保证数据的一致性（DRC和精卫都是这么一个组件）。<br />![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/198393/1563421699888-33a9eafe-480d-40f9-a4e5-bb7456ed638c.png#align=left&display=inline&height=156&margin=%5Bobject%20Object%5D&name=image.png&originHeight=190&originWidth=457&size=17040&status=done&style=none&width=375)<br />

<a name="GVYon"></a>
### 预备知识——DRC
<a name="UUiJ6"></a>
#### 是什么
DRC(Data Replication Center) 数据复制中心，是阿里巴巴数据库技术团队自主研发的实时数据流基础设施。DRC提供了实时数据库数据记录变更的订阅服务，以及同构和异构数据库之间实时同步的服务。<br /> 
<a name="C9Rop"></a>
#### 为什么
由于有很多系统都需要获得实时的增量数据，但是存在以下两个无法回避的问题：

1. DB类型有很多种，MySQL、HBase、Oracle、OceanBase 等等，如果一个系统需要数据，就可能需要与各种不同的DB进行交互， 非常麻烦。
1. 如果所有的系统都是直接连上DB，会对DB造成非常压力。导致DB服务性能下降。

![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/198393/1563469776693-dfc2b9e0-2742-4bbe-b12a-320f13fb58bf.png#align=left&display=inline&height=187&margin=%5Bobject%20Object%5D&name=image.png&originHeight=259&originWidth=554&size=30996&status=done&style=none&width=400)<br />DRC主要解决的就是这两个问题，它具备多种数据库的日志解析能力，包括AliSQL，RDS，Oracle，OB，HBase等，DRC的下游只需要通过DRC client订阅到各种数据库的实时数据。<br /> 
<a name="tkg77"></a>
#### 怎么做
如下图所示，drc主要包括以下几个组件：<br />Store ：一个数据源的数据抓取进程，自动读取所连接数据源的日志增量信息，并转换为drc消息暂存在自己这（默认24小时自动删除）；<br />Topic ：数据源的抽象（对应图中mysql中binlog的某段数据【DRC只接受row模式】）；<br />ZooKeeper (ZK)-元数据节点：提供数据源的元数据存储；<br />ClusterManger (CM) -集群控制节点：对用户的身份、权限进行验证，并响应其发送的请求；<br />Client：数据消费客户端，与用户直接交互。<br />![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/198393/1563474613341-5fc18bc2-13ea-480d-a7c6-acf8506ced08.png#align=left&display=inline&height=310&margin=%5Bobject%20Object%5D&name=image.png&originHeight=301&originWidth=554&size=36333&status=done&style=none&width=570)<br />自主消费方式如下（参考上图步骤）：<br />1、 用户将自己的需求，通过Client 发送到CM，包括TOPIC、用户名、密码、时间点等信息。其中TOPIC就是用户需要请求的数据的描述（包括所需数据源的元数据信息和请求起始位置等）。<br />2、 CM验证用户的身份后，从ZK节点拉取store元数据列表，查找符合用户需求的STORE。<br />3、 CM将匹配上的STORE的信息（主机名、端口等信息）返回给Client。<br />4、 Client 通过这些信息连接STORE，持续获得最新的增量数据。<br /> <br />自动数据同步方式：<br />Congo是专门用于做同步数据的Client。和所有Client一样，使用的是相同的协议，它只是在普通的Client上包装了一层执行逻辑，将从STORE拿到的数据同步到另一个库中（类似于mysql主从同步的sql线程干的事）。<br />![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/198393/1563477334658-25379686-bdf5-45e4-8ba2-5454b6ecf31e.png#align=left&display=inline&height=152&margin=%5Bobject%20Object%5D&name=image.png&originHeight=239&originWidth=602&size=11906&status=done&style=none&width=384)<br />【注意】“双向同步”（即双方数据库都利用drc链接了对方做数据同步）可能产生“数据循环复制”（从对方binlog复制过来的操作在本地也会形成binlog被对方复制走，形成循环）<br />——解决方法：1. binlog记录server-id；（默认）2.[ 自定义标记sql法](https://www.bbsmax.com/A/o75NLqezW3/)。<br />

<a name="l37d4"></a>
## 精卫基本原理
在精卫视角里，数据库、Tair、OpenSearch、MetaQ、ODPS、自定义等都只是不同功能的数据系统。所以抽象起来，精卫解决的是两个数据系统之间的数据复制（Replication）问题。<br />精卫是一个采用Single Leader模型的异步数据复制系统。这种方面临的问题主要有一致性如何保障、Leader不可用、复制延迟（Replication Lag）以及由此引发的多种不一致问题（如 read-after-write consistency, monotonic reads, consistent prefix reads 等）。<br /> <br />![task-type.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/46860/1555664539552-b1514209-f5cc-464b-84af-80d1a3b6d508.png#align=left&display=inline&height=336&margin=%5Bobject%20Object%5D&name=task-type.png&originHeight=395&originWidth=282&size=23916&status=done&style=none&width=240)<br /> <br />精卫的数据源（即Single Leader 复制模型中的Leader）只有数据库一种类型。目标端（即Single Leader复制模型中的Follower）包括数据库、OpenSearch、Tair、MetaQ、自定义等。数据复制包括现有数据（全量）和新增数据（增量）复制两部分。（全量复制可以形式化的证明其本质跟增量复制相同，所以这里只讲增量复制)<br /> <br />精卫使用的是binlog的Row格式，该格式按照**时间顺序精确**的记录了数据库中**每张表结构**和**每行数据**的变更。表结构的变更称为DDL，数据的变更称为DML。精卫只同步DDL记录，DML变更包括三种事件类型，即INSERT, UPDATE, DELETE。<br />![](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/46860/1555899511197-9494e901-e694-444d-a1d0-575ee2b85896.png#align=left&display=inline&height=296&margin=%5Bobject%20Object%5D&originHeight=296&originWidth=579&status=done&style=none&width=579)<br />在精卫视角里，可以简单把Binlog看成一个按照时间顺序由DML三种事件组成的消息队列，精卫数据同步的过程实际是消费这个队列的过程。<br /> <br />在TDDL体系下，若你的逻辑库分布在N个物理库上，那么精卫是在消费这N个消息队列，其中每个队列是按照顺序消费，全局不保证顺序。<br />![jingwei model.png](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/46860/1555909984813-b6724e73-f65d-4a8d-9964-b638375a9cc5.png#align=left&display=inline&height=299&margin=%5Bobject%20Object%5D&name=jingwei%20model.png&originHeight=640&originWidth=1595&size=142456&status=done&style=none&width=746)<br /> <br />每个Binlog队列对应精卫的一个同步任务，每个任务运行在一个单独的JVM进程里。<br />从资源维度来看，精卫由若干集群组成，每个集群包含几百到上千台容器，精卫任务在集群中进行调度，一台容器中通常会分配到多个任务。<br /> 
